# Mission : **Construire un √âcosyst√®me Data Centr√© sur Data Musical avec Python, FastAPI et Streamlit** 

**Contexte : Plongez dans l‚Äôunivers de l'industrie musicale et de la Data Science**


Imaginez une entreprise fictive, **SoundStream Analytics**, qui souhaite r√©volutionner la compr√©hension des tendances musicales gr√¢ce √† une plateforme intelligente exploitant les donn√©es de musiques. Leur ambition ? **Cr√©er un syst√®me ultra-performant d'analyse du comportement des auditeurs** √† destination des labels discographiques, des curateurs de playlists et des plateformes de streaming.  

Mais il y a un probl√®me... **Leurs donn√©es sont dans un √©tat chaotique !** 
Les informations sur les artistes sont incompl√®tes, les habitudes d'√©coute des utilisateurs sont √©parpill√©es et les relations sociales entre fans sont inexploitables. Aucun syst√®me centralis√© ne permet de requ√™ter efficacement les informations sur l'intensit√© d'√©coute d'un artiste (weight), les tags associ√©s par la communaut√© ou les recommandations bas√©es sur les profils similaires.


C'est l√† **que vous entrez en jeu**, en tant que **Consultant Data & Architecte API** ! Votre mission ? Transformer ce chaos en un √©cosyst√®me data structur√©, fluide et performant. Vous serez **le chef d‚Äôorchestre** de ce projet, portant successivement trois casquettes :


---

## **Phase 1 : D√©veloppeur Python & Architecte API**  

![](architecture.png)

**Objectif : Construire une API robuste pour centraliser et exposer les donn√©es Last.fm.**  

üîπ **Design de la base de donn√©es** :  
- Mod√©liser la base de donn√©es en SQL √† partir des fichiers .dat.  
- Utiliser **SQLite** pour stocker les donn√©es de mani√®re efficace.  
- G√©rer les relations **Many-to-Many** sophistiqu√©es : les √©coutes d'artistes par les utilisateurs, les marquages par tags et le graphe social d'amiti√©.  

üîπ **D√©veloppement de l‚ÄôAPI avec FastAPI** :  
- Concevoir un **API RESTful** permettant d'interroger facilement le catalogue musical et les comportements utilisateurs.  
- Int√©grer **Pydantic** pour une validation stricte et un typage fort des donn√©es entrantes et sortantes.  
- Utiliser **SQLAlchemy** pour la gestion des requ√™tes √† la base de donn√©es.  
- Impl√©menter une logique m√©tier avanc√©e : recherche multicrit√®res par tags, statistiques globales et moteur de recommandation collaborative.

üîπ **Qualit√© et Tests** :

- D√©velopper une suite de **tests automatis√©s** pour valider chaque endpoint (CRUD, Health Check, Analytics).
- Assurer la robustesse des endpoints face aux erreurs (gestion des 404, validation des formats).
- G√©n√©rer une documentation interactive automatique via **Swagger**.

üîπ **D√©ploiement de l‚ÄôAPI** :  
- H√©berger l‚ÄôAPI sur un cloud public (**Render, AWS, Azure, GCP**).  
- Conteneuriser l'application avec **Docker** pour garantir un d√©ploiement "on-premise" ou Cloud sans friction.  
- S√©curiser les endpoints et optimiser les performances.  

üîπ **Cr√©ation d‚Äôun SDK en Python** :  
- D√©velopper un **package Python** permettant aux utilisateurs d'interagir facilement avec l‚ÄôAPI.  
- Publier ce package sur **PyPI**, afin qu‚Äôil puisse √™tre utilis√© dans d'autres projets.  

**Livrables** :  
- Une base de donn√©es centralis√©e et pr√™te √† l‚Äôemploi.  
- Une API FastAPI document√©e et d√©ploy√©e.  
- Un SDK Python simple d'utilisation et bien document√©
- Un script de test complet garantissant la fiabilit√© de l'√©cosyst√®me.

---

## **Phase 2 : Data Analyst - Exploration et Visualisation**  

![](architecturephase.png)

**Objectif : Explorer les comportements d'√©coute et visualiser les tendances musicales en interrogeant l‚ÄôAPI.**  

üîπ **Analyse Exploratoire des Donn√©es (EDA)** :  
- Utiliser le **SDK Python** pour requ√™ter l‚ÄôAPI et r√©cup√©rer les donn√©es.  
- Analyser la distribution des poids d'√©coute (weight) pour identifier les artistes "superstars" vs la "longue tra√Æne".  
- √âtudier les genres les plus populaires et les pr√©f√©rences des utilisateurs.  

üîπ **Construction d‚Äôune Data App avec Streamlit** :  
- Cr√©er une **application interactive** qui permet de visualiser les tendances du cin√©ma.    
- √âtudier la structure du **graphe social** : corr√©lation entre le nombre d'amis et la diversit√© des artistes √©cout√©s.
- Mapper les **nuages de tags** pour identifier les genres dominants et les niches musicales.

üîπ **Construction d‚Äôune Data App avec Streamlit** :

D√©velopper une **application interactive** qui se connecte en temps r√©el √† votre API FastAPI.

Cr√©er un **Dashboard de Recommandation** : l'utilisateur saisit son ID et l'app affiche visuellement les artistes sugg√©r√©s par votre algorithme.

Int√©grer des **visualisations dynamiques** : top 10 des artistes les plus √©cout√©s, r√©partition g√©ographique ou temporelle des tags.

Offrir un **moteur de recherche granulaire** permettant de filtrer les artistes par combinaisons de tags et popularit√©.

**Livrables** :  
- Un **Notebook Python** d√©taillant l'analyse statistique des habitudes d'√©coute.  
- Une **application web Streamlit** connect√©e √† l'√©cosyst√®me, transformant les donn√©es brutes de l'API en insights strat√©giques pour les curateurs musicaux.

---

## **Pourquoi cette mission est incontournable pour tout Consultant Data ?**  

- **Exp√©rience compl√®te et immersive** : Vous touchez **√† toutes les facettes** d‚Äôun projet Data moderne, de la structuration SQL √† la recommandation intelligente.  
- **Projet concret et impactant** : Qui n'a jamais r√™v√© d'un syst√®me capable de cartographier les go√ªts musicaux et de pr√©dire le prochain coup de c≈ìur d'un auditeur ?  
- **Comp√©tences ultra-pris√©es** : Vous manipulez **FastAPI, SQLAlchemy, Streamlit, Machine Learning, Cloud, et Docker**.  
- **Un atout pour votre portfolio** : √Ä la fin, vous aurez un projet **cl√© en main**, √† exhiber fi√®rement sur GitHub ou en d√©mo pour vos futurs clients.  

- **Pr√™t √† relever le d√©fi et √† devenir un D√©veloppeur d'API et Data analyst ?** Rejoignez le cours d√®s maintenant et embarquez pour une aventure 100% immersive dans le monde fascinant des donn√©es musicales ! 

---

**BONUS** :  
- Acc√®s au **code source** complet (Backend FastAPI + Tests automatis√©s).  

---

# Dataset MovieLens - Description des Donn√©es

Le dataset utilis√© dans ce projet est un ensemble de donn√©es riche et multidimensionnel inspir√© de la plateforme Last.fm. Il permet de mod√©liser non seulement les catalogues musicaux, mais aussi les comportements sociaux et les pr√©f√©rences subjectives. Ce dataset est le terrain de jeu id√©al pour construire des syst√®mes de recommandation collaboratifs et des API capables de g√©rer des relations complexes √† grande √©chelle.

## Fichiers et Structure des Donn√©es

### 1. artists.dat
Contient la liste des artistes musicaux avec leurs m√©tadonn√©es de base.

**Colonnes :**
- `id` : Identifiant unique de l'artiste (cl√© primaire).
- `name` : Nom officiel de l'artiste ou du groupe.
- `url` : Lien vers la page de l'artiste sur le site Last.fm.
- `pictureURL` : URL de l'image ou de l'avatar de l'artiste.

**Exemple :**
```
id,name,url,pictureURL
1,MALICE MIZER,http://www.last.fm/music/MALICE+MIZER,http://userserve-ak.last.fm/serve/252/1083.jpg
2,Diary of Dreams,http://www.last.fm/music/Diary+of+Dreams,http://userserve-ak.last.fm/serve/252/3052066.jpg
```

---

### user_artists.dat
Contient les statistiques d'√©coute des utilisateurs. C'est le c≈ìur de l'analyse comportementale.

**Colonnes :**
- `userID` : Identifiant unique de l'utilisateur (cl√© √©trang√®re vers `User`).
- `artistID` : Identifiant de l'artiste √©cout√© (cl√© √©trang√®re vers `Artist`).
- `weight` : Poids de l'√©coute, repr√©sentant le nombre total de lectures (plays) effectu√©es par cet utilisateur pour cet artiste.

**Exemple :**
```
userID,artistID,weight
2,51,13883
4,52,11690
```

---

### 3. user_taggedartists.dat
Contient les √©tiquettes (tags) appliqu√©es par les utilisateurs aux artistes pour les cat√©goriser.

**Colonnes :**
- `userID` : Identifiant de l'utilisateur ayant pos√© le tag.
- `artistID` : Identifiant de l'artiste concern√©.
- `tagID` : Identifiant du tag (r√©f√©rence vers la table Tag).
- `timestamp` : Horodatage UNIX du moment o√π l'artiste a √©t√© tagu√©.

**Exemple :**
```
userID,artistID,tagID,timestamp
2,52,13,1235396034
2,52,15,1235396034
```

---

### 4. user_friends.dat
Contient le graphe social de la plateforme, indispensable pour les recommandations collaboratives.

**Colonnes :**
- `userID` : Identifiant de l'utilisateur.
- `friendID` : Identifiant de l'utilisateur ami.
**Note** : Dans votre application, cette relation est bidirectionnelle et permet de construire des cercles d'influence musicale.

**Exemple :**
```
userID,friendID
2,275
2,428
```

---
### 5. tags.dat
Table de r√©f√©rence contenant la valeur textuelle des identifiants de tags utilis√©s.

**Colonnes :**
- `tagID` : Identifiant unique du tag.
- `tagValue` : Libell√© du tag (ex: "rock", "80s", "female vocalists").

**Exemple :**
```
tagID,tagValue
13,chillout
15,ambient
```

---

## Structure de la Base de Donn√©es SQLite3

Pour orchestrer cet √©cosyst√®me musical, nous avons d√©fini le sch√©ma relationnel suivant :

### Table `artists`
```sql
CREATE TABLE artists (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    url TEXT,
    pictureURL TEXT
);
```

### Table `users`
```sql
CREATE TABLE users (
    userID INTEGER PRIMARY KEY
);
```

### Table `user_artists`
```sql
CREATE TABLE user_artists (
    userID INTEGER,
    artistID INTEGER,
    weight INTEGER NOT NULL,
    PRIMARY KEY (userID, artistID),
    FOREIGN KEY (userID) REFERENCES users(userID) ON DELETE CASCADE,
    FOREIGN KEY (artistID) REFERENCES artists(id) ON DELETE CASCADE
);
```

### Table `tags`
```sql
CREATE TABLE tags (
    tagID INTEGER PRIMARY KEY AUTOINCREMENT,
    tagValue TEXT NOT NULL UNIQUE
);
```

### Table `user_taggedartists`
```sql
CREATE TABLE user_taggedartists (
    userID INTEGER,
    artistID INTEGER,
    tagID INTEGER,
    timestamp INTEGER NOT NULL,
    day INTEGER,
    month INTEGER,
    year INTEGER,
    PRIMARY KEY (userID, artistID, tagID, timestamp),
    FOREIGN KEY (userID) REFERENCES users(userID) ON DELETE CASCADE,
    FOREIGN KEY (artistID) REFERENCES artists(id) ON DELETE CASCADE,
    FOREIGN KEY (tagID) REFERENCES tags(tagID) ON DELETE CASCADE
);
```

### Table `user_friends`
```sql
CREATE TABLE user_friends (
    userID INTEGER,
    friendID INTEGER,
    PRIMARY KEY (userID, friendID),
    FOREIGN KEY (userID) REFERENCES users(userID) ON DELETE CASCADE,
    FOREIGN KEY (friendID) REFERENCES users(userID) ON DELETE CASCADE
);
```

## Relations entre les Tables
- **Cl√©s √âtrang√®res** : Les tables `user_artists`, `user_taggedartists` et `user_friends` servent de ponts relationnels. Elles assurent que chaque interaction (√©coute, tag ou amiti√©) est rattach√©e √† des entit√©s existantes.
- **Int√©grit√© R√©f√©rentielle** : L'utilisation de `ON DELETE CASCADE` garantit que si un artiste ou un utilisateur est supprim√©, toutes ses interactions li√©es sont automatiquement nettoy√©es, √©vitant ainsi les donn√©es orphelines.
- **Cl√©s Composites** : Pour les √©coutes et les amiti√©s, nous utilisons des cl√©s primaires composites (ex: `userID + artistID`) pour garantir l'unicit√© des relations et optimiser les performances de recherche.

Cette architecture transforme des fichiers plats en un graphe de donn√©es interconnect√©, id√©al pour alimenter vos algorithmes de recommandation et vos tableaux de bord analytiques.


# Cr√©ation de la Base de Donn√©es SQLite3 et de ses tables

```bash
(.venv) vant@MOOVE15:~/D:/End_To_End_Data_Science_Project/Artirst_Backend$ sqlite artist.db
```

```sql
CREATE TABLE artists (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    url TEXT,
    pictureURL TEXT
);
```

```sql
CREATE TABLE users (
    userID INTEGER PRIMARY KEY
);
```

```sql
CREATE TABLE user_artists (
    userID INTEGER,
    artistID INTEGER,
    weight INTEGER NOT NULL,
    PRIMARY KEY (userID, artistID),
    FOREIGN KEY (userID) REFERENCES users(userID) ON DELETE CASCADE,
    FOREIGN KEY (artistID) REFERENCES artists(id) ON DELETE CASCADE
);
```

```sql
CREATE TABLE tags (
    tagID INTEGER PRIMARY KEY AUTOINCREMENT,
    tagValue TEXT NOT NULL UNIQUE
);
```

```sql
CREATE TABLE user_taggedartists (
    userID INTEGER,
    artistID INTEGER,
    tagID INTEGER,
    timestamp INTEGER NOT NULL,
    day INTEGER,
    month INTEGER,
    year INTEGER,
    PRIMARY KEY (userID, artistID, tagID, timestamp),
    FOREIGN KEY (userID) REFERENCES users(userID) ON DELETE CASCADE,
    FOREIGN KEY (artistID) REFERENCES artists(id) ON DELETE CASCADE,
    FOREIGN KEY (tagID) REFERENCES tags(tagID) ON DELETE CASCADE
);
```

```sql
CREATE TABLE user_friends (
    userID INTEGER,
    friendID INTEGER,
    PRIMARY KEY (userID, friendID),
    FOREIGN KEY (userID) REFERENCES users(userID) ON DELETE CASCADE,
    FOREIGN KEY (friendID) REFERENCES users(userID) ON DELETE CASCADE
);
```

# Chargement des Donn√©es dans les Tables SQLite3

## Activation des cl√©s √©trang√®res

```sql
PRAGMA foreign_keys = ON;
```

La commande **`PRAGMA foreign_keys = ON;`** dans SQLite sert √† **activer les cl√©s √©trang√®res**.  Cela garantit que toutes les contraintes de cl√©s √©trang√®res seront respect√©es.

### **Explication** :

- SQLite **ne v√©rifie pas** les contraintes de cl√© √©trang√®re par d√©faut.
- Cette commande **active** l'int√©grit√© r√©f√©rentielle, ce qui signifie que :
  - Une valeur de cl√© √©trang√®re doit correspondre √† une cl√© primaire existante.
  - Si une ligne r√©f√©renc√©e est supprim√©e ou modifi√©e, cela peut entra√Æner une erreur ou d√©clencher une action d√©finie (ex: `ON DELETE CASCADE`).

### **Bonnes pratiques** :

- Toujours activer les cl√©s √©trang√®res en d√©but de session SQLite :
  ```sql
  PRAGMA foreign_keys = ON;
  ```
- Pour v√©rifier si les cl√©s √©trang√®res sont activ√©es :
  ```sql
  PRAGMA foreign_keys;
  ```
  - Retourne `1` si activ√©, `0` sinon.


## Pr√©parez l'instruction d'importation pour reconna√Ætre le format CSV avec la commande suivante¬†:

```sql
.separator "\t"
```

## Chargement des donn√©es des fichiers csv dans les tables

### Chargement

```sql
.import --skip 1 Data/artists.dat artists
```

```sql
.import --skip 1 Data/user_artists.dat user_artists
```

```sql
.import --skip 1 Data/tags.dat tags
```

```sql
.import --skip 1 Data/user_taggedartists.dat user_taggedartists
```

```sql
.import --skip 1 Data/user_friends.dat user_friends
```

### **V√©rifions que les donn√©es ont √©t√© charg√©es** :

```sql
SELECT * FROM artists LIMIT 2;
```

```
1,"MALICE MIZER","http://www.last.fm/music/MALICE+MIZER","http://images.last.fm/1083.jpg"
2,"Diary of Dreams","http://www.last.fm/music/Diary+of+Dreams","http://images.last.fm/30520.jpg"
```

```sql
SELECT COUNT(*) AS total_artists FROM artists;
```

```
2101
```

```sql
SELECT COUNT(*) AS total_listens FROM user_artists;
```

```
92834
```

```sql
SELECT userID, artistID, weight FROM user_artists LIMIT 3;
```

```
2,51,13883
2,52,11690
2,53,11351
```

Pour quitter l'interface en lignes de commandes de SQLite, tapez cette commande :

```sql
.exit
```

# Phase 1 : D√©veloppeur Python & Architecte API

## Introduction

![](architecture.png)


### Explication du diagramme

Une API (Application Programming Interface) est une interface qui permet √† des applications ou des utilisateurs d'interagir avec un syst√®me. Ce diagramme repr√©sente comment une API fonctionne pour g√©rer des donn√©es et interagir avec une base de donn√©es.

#### √âtape par √©tape :

1. **Les utilisateurs de l'API** (`API Users`)  
   - Ce sont les personnes ou applications qui utilisent l'API pour envoyer ou r√©cup√©rer des donn√©es.
   - Pour interagir avec l'API, ils utilisent un **SDK** (Software Development Kit), qui est une biblioth√®que (un package) Python facilitant l'envoi de requ√™tes.

2. **Le transfert et la validation des donn√©es** (`Pydantic`)  
   - Lorsque l'utilisateur envoie des requ√™tes √† l'API, elles passent d'abord par **Pydantic**.  Nous parlerons davantage de Pydantic dans une autre session.
   - Pydantic v√©rifie que les donn√©es sont correctes (par exemple, s'il manque une valeur ou si un type est incorrect).  

3. **Le contr√¥leur API** (`FastAPI`)  
   - FastAPI est le c≈ìur de l'API. Il re√ßoit les requ√™tes des utilisateurs, traite les donn√©es et d√©cide de ce qu'il faut faire (ex. : ins√©rer de nouvelles donn√©es, r√©cup√©rer des informations, etc.).
   - Il agit comme un interm√©diaire entre l'utilisateur et la base de donn√©es.

4. **Les classes de base de donn√©es** (`SQLAlchemy`)  
   - SQLAlchemy est une biblioth√®que qui permet de communiquer avec la base de donn√©es de mani√®re organis√©e.
   - Il traduit les requ√™tes Python en instructions compr√©hensibles par la base de donn√©es.

5. **La base de donn√©es** (`SQLite`)  
   - SQLite est la database o√π se trouve les donn√©es.
   - L'API envoie des requ√™tes pour r√©cup√©rer des donn√©es de la database SQLite.

#### En r√©sum√© :
- L'utilisateur envoie des donn√©es via l'**SDK**.
- Ces donn√©es sont **valid√©es** (`Pydantic`).
- L'API d√©cide quoi faire (`FastAPI`).
- Si n√©cessaire, elle stocke ou r√©cup√®re des donn√©es via **SQLAlchemy**.
- La base de donn√©es **SQLite** garde les informations de mani√®re structur√©e.

---

L'API fonctionne comme un **restaurant moderne avec une tablette pour commander** :  

1. **Le client (API Users)** arrive au restaurant et veut commander un plat.  
2. **Le menu num√©rique (SDK en Python)** lui permet de passer commande facilement sans parler directement au serveur. Il peut s√©lectionner un plat en quelques clics.  
3. **Le serveur (FastAPI)** re√ßoit la commande, la v√©rifie et la transmet en cuisine.  
4. **Le chef (SQLAlchemy)** pr√©pare le plat en r√©cup√©rant les ingr√©dients depuis **la r√©serve (SQLite, la base de donn√©es)**.  
5. Une fois le plat pr√™t, **le serveur revient avec la commande** et la sert au client.  

**Pourquoi le SDK est important ?**  
C‚Äôest comme une tablette qui facilite la commande : au lieu d‚Äô√©crire une requ√™te compliqu√©e ou d‚Äôappeler directement le serveur, le client peut utiliser une interface simple et intuitive (le SDK) pour interagir avec l‚ÄôAPI.


## Classes SQLAlchemy

### Pourquoi utiliser SQLAlchemy dans notre API ?  

Lorsque vous cr√©ez une application qui interagit avec une base de donn√©es, comme notre API de films, vous avez deux choix pour g√©rer les donn√©es :  

1. **Ex√©cuter des requ√™tes SQL directement**  
   - Vous devez √©tablir une connexion avec SQLite.  
   - Vous √©crivez des requ√™tes SQL brutes pour ins√©rer, r√©cup√©rer et modifier des donn√©es.  
   - Vous devez g√©rer manuellement les types de donn√©es (convertir entre les formats SQLite et Python).  
   - Il faut se prot√©ger contre les attaques par injection SQL.  

2. **Utiliser un ORM (Object-Relational Mapper) comme SQLAlchemy**  
   - SQLAlchemy permet d‚Äôinteragir avec la base de donn√©es en manipulant des objets Python au lieu d‚Äô√©crire du SQL brut.  
   - Il simplifie la gestion des requ√™tes tout en garantissant la s√©curit√© contre les injections SQL.  
   - Il convertit automatiquement les donn√©es entre Python et SQLite.  
   - Il facilite la migration de la base de donn√©es si on change de moteur SQL (ex: passer de SQLite √† PostgreSQL).  

Dans notre projet, SQLAlchemy joue un r√¥le cl√© dans la couche "Database Classes". Il agit comme **un interm√©diaire entre notre API (FastAPI) et la base de donn√©es (SQLite)**, en traduisant les requ√™tes API en op√©rations sur la base de donn√©es tout en maintenant un code propre et s√©curis√©. 

---

Pour utiliser SQLAlchemy, nous devons pr√©alablement l'installer dans notre environnement virtuel :

```bash
pip install sqlalchemy
```

---


# Fichiers n√©cessaires pour requ√™ter la database SQLite √† l'aide de Python

### database.py

```python
"""Database configuration"""
from sqlalchemy import create_engine
from sqlalchemy.orm import declarative_base
from sqlalchemy.orm import sessionmaker

SQLALCHEMY_DATABASE_URL = "sqlite:///./artist.db"

# # Cr√©er un moteur de base de donn√©es (engine) qui √©tablit la connexion avec notre base SQLite (movies.db).
engine = create_engine(
    SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False}
)

# D√©finir SessionLocal, qui permet de cr√©er des sessions pour interagir avec la base de donn√©es.
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# D√©finir Base, qui servira de classe de base pour nos mod√®les SQLAlchemy.
Base = declarative_base()

# # Optionnel : pour ex√©cuter une v√©rification de la connexion √† la base de donn√©es
# # (peut √™tre utile pour le d√©bogage ou la configuration initiale).
# if __name__ == "__main__":
#     try:
#         with engine.connect() as conn:
#             print("Connexion √† la base de donn√©es r√©ussie.")
#     except Exception as e:
#         print(f"Erreur de connexion : {e}")
```

---

Voici une explication claire et simple de ce que font les trois instructions, avec un focus sur **les arguments** :

#### 1. `create_engine(...)`

```python
engine = create_engine(
    SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False}
)
```

Cette ligne **cr√©e un moteur de base de donn√©es SQLAlchemy** qui va permettre √† ton application Python d‚Äôinteragir avec la base SQLite.

##### Explication des arguments :
- **`SQLALCHEMY_DATABASE_URL`** : c‚Äôest l‚ÄôURL de connexion √† ta base. Exemple ici :
  ```
  "sqlite:///./artist.db"
  ```
  > Cela veut dire : utiliser SQLite et se connecter √† un fichier nomm√© `artist.db` situ√© dans le m√™me dossier que ce fichier Python.

- **`connect_args={"check_same_thread": False}`** :
  - SQLite, par d√©faut, **interdit l'utilisation de la m√™me connexion dans plusieurs threads**.
  - Or, FastAPI (et d'autres frameworks web) peuvent utiliser du **multithreading** pour g√©rer plusieurs requ√™tes en parall√®le.
  - Donc `check_same_thread=False` **d√©sactive cette restriction**.
  - Attention : √Ä utiliser uniquement si **tu g√®res bien les sessions SQLAlchemy** (ce que fait FastAPI avec d√©pendances `Depends()`).

---

#### 2. `sessionmaker(...)`

```python
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
```

`sessionmaker` est une **fabrique de sessions**. Tu l‚Äôutilises pour cr√©er des sessions qui vont te permettre de lire/√©crire dans la base de donn√©es.

##### Explication des arguments :
- **`autocommit=False`** :
  - Cela signifie que **tu dois valider les transactions manuellement** (avec `.commit()`).
  - C‚Äôest plus s√ªr : tu peux rollback en cas d‚Äôerreur.

- **`autoflush=False`** :
  - Si c'√©tait `True`, SQLAlchemy enverrait automatiquement les changements en base **avant certaines requ√™tes SELECT**.
  - Ici, on veut plus de contr√¥le. Donc on met `False` : les changements sont flush√©s **manuellement ou au moment du commit**.

- **`bind=engine`** :
  - Lie la session √† l‚Äô**engine** que tu as cr√©√© plus haut.
  - Ainsi, toutes les sessions cr√©√©es avec `SessionLocal()` vont utiliser la base `movies.db`.


##### üß™ Exemple d'utilisation de `SessionLocal` :

```python
db = SessionLocal()
try:
    movies = db.query(Movie).all()
finally:
    db.close()
```

---

#### 3. `declarative_base()`

```python
from sqlalchemy.orm import declarative_base

Base = declarative_base()
```

Cette ligne cr√©e une **classe de base** nomm√©e `Base` √† partir de laquelle **tous tes mod√®les (tables)** vont h√©riter.


##### Pourquoi c‚Äôest utile ?

Lorsque tu d√©finis une classe comme ceci :

```python
class Artist(Base):
    __tablename__ = "artists"
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, index=True)
    url = Column(String)
    pictureURL = Column(String)
```

Tu es en train de cr√©er :
- une **classe Python** (`Artist`) : que vous pouvez manipuler dans votre code FastAPI.
- Un **lien direct avec une table SQL** (`artists`) : qui sera cr√©√©e dans votre fichier `artist.db`.
- Des colonnes structur√©es (`id`, `name`, `url‚Ä¶`) : avec des types de donn√©es pr√©cis (Integer, String).

Mais pour que SQLAlchemy comprenne que `Artist` doit √™tre **une table dans la base de donn√©es**, il faut qu‚Äôelle h√©rite d‚Äôune **classe parente sp√©ciale**, et c‚Äôest justement ce que `Base = declarative_base()` fournit.

##### En r√©sum√© :

| √âl√©ment                  | R√¥le                                                                 |
|--------------------------|----------------------------------------------------------------------|
| `declarative_base()`     | Cr√©e une superclasse `Base`                                          |
| `Base`                   | Sert de base √† tous tes mod√®les SQLAlchemy                          |
| Classe qui h√©rite de `Base` | Devient une table dans la base de donn√©es via la **declarative mapping** |


### import_data.py

Le script d'importation est le moteur qui permet de transformer vos fichiers plats (au format `.dat`) en une base de donn√©es relationnelle structur√©e. Il assure que les donn√©es brutes de Last.fm sont nettoy√©es, valid√©es et ins√©r√©es dans le bon ordre pour respecter l'int√©grit√© de votre syst√®me.


#### 1. Pourquoi ce script est-il crucial ?

- Importer **tous les fichiers** .dat **dans le bon ordre**
- Cr√©er automatiquement les **utilisateurs manquants**
- G√©rer correctement les **timestamps invalides ou manquants**
- Optimiser les performances gr√¢ce aux **insertions par batch**
- Afficher une **progression claire et en temps r√©el**
- V√©rifier la **coh√©rence finale des donn√©es import√©es**

#### 2. Architecture g√©n√©rale

Le script repose sur trois composants principaux :

- **SQLAlchemy ORM** : D√©finition des mod√®les (User, Artist, Tag, etc.) et Mapping objet‚Äìrelationnel propre et maintenable
- **Fichiers `.dat` Last.fm** : Sources de donn√©es brutes
- **Pipeline d‚Äôimportation** : Fonctions d√©di√©es √† chaque table et Gestion centralis√©e via import_all_data()


```python
"""Script d'importation des donn√©es Last.fm"""
from sqlalchemy import Column, Integer, String, Float, ForeignKey
from sqlalchemy.orm import relationship # permet des relations de cl√© √©trang√®re entre les tables.
from database import Base
```
###### Configuration des donn√©es
```python
DATA_DIR = "D:/End_To_End_Data_Science_Project/Artirst_Backend/Data"
```
Ce param√®tre d√©finit le dossier contenant tous les fichiers `.dat`. Il est v√©rifi√© automatiquement avant toute importation afin d‚Äô√©viter les erreurs d‚Äôex√©cution.

###### Cr√©ation des tables
```python
def create_tables():
    Base.metadata.create_all(bind=engine)
```
Cr√©e toutes les tables d√©finies dans les mod√®les SQLAlchemy. Respecte automatiquement les cl√©s primaires et √©trang√®res. √âvite toute cr√©ation manuelle c√¥t√© SQL

###### Importation des artistes `(artists.dat)`
- Lecture ligne par ligne du fichier
- Conversion en objets Artist
- Insertion par batch (1000 lignes)

```python
db.bulk_save_objects(batch)
db.commit()
```
Cette m√©thode am√©liore fortement les performances par rapport aux insertions unitaires.


###### Importation des tags (`tags.dat`)
Fonction : `import_tags`
- Encodage sp√©cifique (latin-1) pour √©viter les erreurs de caract√®res
- Stockage des identifiants et libell√©s des tags
- Insertion optimis√©e par batch

###### Importation des √©coutes (`user_artists.dat`)
Fonction : `import_user_artists`
Cette √©tape est cl√© car :
- Elle cr√©e automatiquement les utilisateurs manquants
- Elle enregistre le nombre d‚Äô√©coutes (weight) par artiste

```python
if user_id not in users_seen:
    user = User(userID=user_id)
```
Cela garantit l‚Äôint√©grit√© r√©f√©rentielle sans pr√©traitement manuel.


###### Gestion intelligente des timestamps
Fonction : `import_user_tagged_artists`

- EConversion s√©curis√©e des timestamps Last.fm (en millisecondes)
- Extraction automatique : day, month, year
- Gestion des timestamps invalides (0, valeurs hors plage)

```python
try:
    dt = datetime.fromtimestamp(timestamp / 1000)
except (OSError, ValueError, OverflowError):
    pass
```
Cette logique √©vite les erreurs critiques tout en conservant un maximum d‚Äôinformations exploitables pour l‚Äôanalyse temporelle.


###### Importation des relations d‚Äôamiti√© (`user_friends.dat`)
Fonction : `import_user_friends`

- Stocke les relations utilisateur ‚Üî ami
- Compatible avec des analyses de graphes sociaux
- Insertion rapide par batch


###### Statistiques finales et validation
Fonction : `display_final_statistics`

Affiche :
- Nombre total d‚Äôartistes
- Utilisateurs
- Tags
- √âcoutes
- Tags appliqu√©s
- Relations d‚Äôamiti√©

Et v√©rifie les incoh√©rences potentielles :

```SQL
SELECT COUNT(*) FROM user_taggedartists WHERE timestamp IS NULL
```
Cela permet une validation imm√©diate de la qualit√© des donn√©es



